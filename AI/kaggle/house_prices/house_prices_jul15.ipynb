{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle competition src:\n",
    "# https://www.kaggle.com/c/house-prices-advanced-regression-techniques/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, GridSearchCV\n",
    "    \n",
    "from sklearn.linear_model import LassoCV, RidgeCV, LinearRegression, ElasticNetCV, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "data_dir_path = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir_path, 'train.csv')) \n",
    "test_df = pd.read_csv(os.path.join(data_dir_path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_test_df = pd.concat([train_df, test_df], ignore_index=True, sort=False)\n",
    "\n",
    "concat_train_test_df = concat_train_test_df.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore loaded data.\n",
    "\n",
    "def display_dataset_overview(dataset_df):\n",
    "    \"\"\"Display basic information about dataset\"\"\"\n",
    "    # Data inside\n",
    "    display(dataset_df.head(3))\n",
    "    display(dataset_df.tail(3))\n",
    "    # Shape\n",
    "    display(dataset_df.shape)\n",
    "    # .describe output\n",
    "    display(dataset_df.describe(include='all').T)\n",
    "    \n",
    "\n",
    "def display_dataset_col_dtypes(dataset_df):\n",
    "    \"\"\"Display dataset columns and its dtypes\"\"\"\n",
    "    # All columns and their dtypes\n",
    "    display(dataset_df.dtypes.unique())\n",
    "    display(dataset_df.select_dtypes(include='int64').columns.values)\n",
    "    display(dataset_df.select_dtypes(include='float64').columns.values)\n",
    "    display(dataset_df.select_dtypes(include='object').columns.values)\n",
    "    display(dataset_df.select_dtypes(include='number').columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_dataset_overview(train_df)\n",
    "\n",
    "# display_dataset_overview(test_df)\n",
    "\n",
    "# display_dataset_overview(concat_train_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore distributions of continuous features in certain dataset\n",
    "\n",
    "def display_hist(dataset_df, col_name, n_bins=25):\n",
    "    \"\"\"Display histogram for dataset[col_name] values\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    dataset_df[col_name].hist(bins=n_bins)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def display_all_numerical_hist(set1_df, set2_df, n_bins=25):\n",
    "    \"\"\"Display histograms for every numerical feature from set1_df and set2_df\"\"\"\n",
    "    concat_df = pd.concat([set1_df, set2_df], ignore_index=True, sort=False)\n",
    "    numeric_col_names = concat_df.select_dtypes(include='number').columns.values\n",
    "    for col_name in numeric_col_names:\n",
    "        fig, [ax_0, ax_1, ax_2] = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        ax_0.set_title('set1 {0}'.format(col_name))\n",
    "        set1_df[col_name].hist(ax=ax_0, bins=n_bins)\n",
    "        ax_1.set_title('set2 {0}'.format(col_name))\n",
    "        set2_df[col_name].hist(ax=ax_1, bins=n_bins)\n",
    "        ax_2.set_title('concat [set1, set2] {0}'.format(col_name))\n",
    "        concat_df[col_name].hist(ax=ax_2, bins=n_bins)\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def display_colx_coly_scatter(dataset_df, x_col_name, y_col_name, color=None):\n",
    "    \"\"\"Display scatterplot for {dataset_df[x_col_name], dataset_df[y_col_name]} values\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sc = plt.scatter(x_col_name, y_col_name, data=dataset_df, c=color)\n",
    "    plt.title(\"{0} - {1}\".format(x_col_name, y_col_name))\n",
    "    plt.xlabel(x_col_name)\n",
    "    plt.ylabel(y_col_name)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_all_numerical_scatter(set1_df, col_to_compare):\n",
    "    \"\"\"Display scatter plots for every numerical feature from set1_df and col_to_compare column values\"\"\"\n",
    "    numeric_col_names = set1_df.select_dtypes(include='number').columns.values\n",
    "    for col_name in numeric_col_names:\n",
    "        display_colx_coly_scatter(set1_df, col_name, col_to_compare, color=col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display_hist(train_df, 'SalePrice', 100)\n",
    "\n",
    "# display_all_numerical_hist(\n",
    "#     train_df.drop(['SalePrice', 'Id'], axis=1),\n",
    "#     test_df.drop('Id', axis=1)\n",
    "# )\n",
    "\n",
    "# display_colx_coly_scatter(train_df, 'GrLivArea', 'SalePrice', color='YearBuilt')\n",
    "\n",
    "# display_all_numerical_scatter(\n",
    "#     train_df.drop(['Id'], axis=1),\n",
    "#     'SalePrice'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore distributions of categorical features in certain dataset\n",
    "\n",
    "def display_col_freqtable(dataset_df, col_name):\n",
    "    \"\"\"Display frequency table for dataset_df[col_name] values\"\"\"\n",
    "    display(\n",
    "        pd.crosstab(\n",
    "            index=dataset_df[col_name],\n",
    "            columns=\"count\"\n",
    "        ).sort_values(by='count', ascending=False)\n",
    "    )\n",
    "\n",
    "\n",
    "def display_all_categorical_freq_bar(set1_df, set2_df):\n",
    "    \"\"\"Display frequency table and barplot for each categorical feature\"\"\"\n",
    "    concat_df = pd.concat([set1_df, set2_df], ignore_index=True, sort=False)\n",
    "    numeric_col_names = concat_df.select_dtypes(include='object').columns.values\n",
    "    for col_name in numeric_col_names:    \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axes[0].set_title('set1 {0}'.format(col_name))\n",
    "        set1_df[col_name].value_counts().plot(kind='bar', ax=axes[0])\n",
    "        display_col_freqtable(set1_df, col_name)\n",
    "        axes[1].set_title('set2 {0}'.format(col_name))\n",
    "        set2_df[col_name].value_counts().plot(kind='bar', ax=axes[1])\n",
    "        display_col_freqtable(set2_df, col_name)\n",
    "        axes[2].set_title('concat_df [set1, set2] {0}'.format(col_name))\n",
    "        concat_df[col_name].value_counts().plot(kind='bar', ax=axes[2])\n",
    "        display_col_freqtable(concat_df, col_name)\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "def display_col_categorical_sns_countplot(dataset_df, col_name):\n",
    "    \"\"\" Display countplot with percentage+cnt for each categorical feature\"\"\"\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = sns.countplot(x=col_name, data=dataset_df)\n",
    "    ax2=ax.twinx()  \n",
    "    ax2.grid(None)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    for p in ax.patches:\n",
    "        x = p.get_bbox().get_points()[:,0]\n",
    "        y = p.get_bbox().get_points()[1,1]\n",
    "        ax.annotate(\n",
    "            '{} | {:.1f}%'.format(int(y), 100. * y / dataset_df[col_name].index.size),\n",
    "            (x.mean(), y),\n",
    "            ha='center', va='bottom'\n",
    "        )\n",
    "    plt.title('Distribution of {0}'.format(col_name))\n",
    "    plt.xlabel('Number of {0}'.format(col_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display_all_categorical_freq_bar(train_df, test_df)\n",
    "\n",
    "# print(\"HouseStyle: train_df\")\n",
    "# display_col_categorical_sns_countplot(train_df, 'HouseStyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore NaN values\n",
    "\n",
    "def display_nan_values(dataset_df):\n",
    "    \"\"\"Display amount of NaN values in dataset_df columns\"\"\"\n",
    "    dataset_df_nans = dataset_df.isnull().sum()\n",
    "    display(dataset_df_nans[dataset_df_nans != 0])\n",
    "\n",
    "\n",
    "def display_all_nan_percentage(dataset_df):\n",
    "    missing_values_cnt = dataset_df.isnull().sum()\n",
    "    missing_values_pct = missing_values_cnt * 100 / len(dataset_df)\n",
    "    missing_values_pct_df = pd.DataFrame({'pct_nan': missing_values_pct, 'cnt_nan': missing_values_cnt})\n",
    "    missing_values_pct_df = missing_values_pct_df.sort_values('pct_nan')\n",
    "    missing_values_pct_df[missing_values_pct_df['pct_nan'] != 0].plot(kind='bar')\n",
    "    display(missing_values_pct_df[missing_values_pct_df['pct_nan'] != 0].T)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def get_rows_with_nan(dataset_df, col_name, max_values=10):\n",
    "    \"\"\"Get rows with np.nan in col_name column values\"\"\"\n",
    "    dataset_isnull_values = dataset_df.isnull()\n",
    "    has_nan_rows = dataset_df.loc[\n",
    "        dataset_isnull_values[dataset_isnull_values[col_name] == True].index, :\n",
    "    ].head(max_values)\n",
    "    return has_nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_all_nan_percentage(train_df)\n",
    "\n",
    "# display_all_nan_percentage(test_df)\n",
    "\n",
    "# display_all_nan_percentage(concat_train_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fix NaN values\n",
    "\n",
    "# display_nan_values(train_df)\n",
    "\n",
    "# display_nan_values(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate arrays\n",
    "\n",
    "train_nonan_df = train_df.copy()\n",
    "test_nonan_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MSZoning\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'MSZoning'))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'MSZoning'))\n",
    "\n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'MSZoning')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'MSZoning')\n",
    "\n",
    "    train_df_cpy = train_nonan_df.copy()\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    train_df_cpy['MSZoning'] = lbl_encoder.fit_transform(train_df_cpy['MSZoning'])\n",
    "    display_colx_coly_scatter(train_df_cpy, 'GrLivArea', 'SalePrice', color='MSZoning')\n",
    "\n",
    "def _local_fix():\n",
    "    # Fix - assume there are some \"other\" zoning.\n",
    "    # todo: try replacing with .mode()\n",
    "    # todo: features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    test_nonan_df['MSZoning'] = test_nonan_df['MSZoning'].fillna('Other')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'MSZoning'))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'MSZoning'))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LotFrontage\n",
    "\n",
    "def _local_disp():\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'LotFrontage', 3000).shape)\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'LotFrontage', 3000).shape)\n",
    "\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'LotFrontage', 3000).head(10))\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'LotFrontage', 3000).head(10))\n",
    "\n",
    "    display_hist(train_nonan_df, 'LotFrontage', n_bins=100)\n",
    "    display_hist(test_nonan_df, 'LotFrontage', n_bins=100)\n",
    "\n",
    "    display_colx_coly_scatter(train_nonan_df, 'LotFrontage', 'LotArea')\n",
    "    display_colx_coly_scatter(test_nonan_df, 'LotFrontage', 'LotArea')\n",
    "\n",
    "    train_df_cpy = train_nonan_df.copy()\n",
    "    lbl_encoder = LabelEncoder()\n",
    "\n",
    "    train_df_cpy['MSZoning'] = lbl_encoder.fit_transform(train_df_cpy['MSZoning'])\n",
    "    display_colx_coly_scatter(train_df_cpy, 'LotFrontage', 'SalePrice', color='MSZoning')\n",
    "    display_colx_coly_scatter(train_df_cpy, 'LotArea', 'SalePrice', color='MSZoning') \n",
    "\n",
    "    train_df_cpy['Neighborhood'] = lbl_encoder.fit_transform(train_df_cpy['Neighborhood'])\n",
    "    display_colx_coly_scatter(train_df_cpy, 'LotFrontage', 'SalePrice', color='Neighborhood')\n",
    "    display_colx_coly_scatter(train_df_cpy, 'LotArea', 'SalePrice', color='Neighborhood') \n",
    "\n",
    "def _local_fix():\n",
    "    # Fix - assume there might be houses without frontage at all.\n",
    "    # todo: try replacing with .mean()\n",
    "    # todo: replace by neighborhood / MSZoning\n",
    "        # features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "    train_nonan_df['LotFrontage'] = train_nonan_df['LotFrontage'].fillna(0.0)\n",
    "    test_nonan_df['LotFrontage'] = test_nonan_df['LotFrontage'].fillna(0.0)\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'LotFrontage'))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'LotFrontage'))\n",
    "\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Alley\n",
    "\n",
    "def _local_disp():\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'Alley', 3000).shape)\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'Alley', 3000).shape)\n",
    "\n",
    "    display(pd.unique(train_nonan_df['Alley']))\n",
    "\n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'Alley')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'Alley')\n",
    "    \n",
    "def _local_fix():\n",
    "    # Fix - there are houses with no Alley access.\n",
    "    # todo: try replacing with .mode() (by dataset, NOT by concatenated)\n",
    "\n",
    "    train_nonan_df['Alley'] = train_nonan_df['Alley'].fillna('NoAccess')\n",
    "    test_nonan_df['Alley'] = test_nonan_df['Alley'].fillna('NoAccess')\n",
    "\n",
    "def _local_check():\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'Alley', 3000).shape)\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'Alley', 3000).shape)\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "def _local_disp():\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'Utilities', 3000))\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'Utilities', 3000))\n",
    "\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'Utilities', 3000))\n",
    "\n",
    "    display(pd.unique(train_nonan_df['Utilities']))\n",
    "    display(pd.unique(test_nonan_df['Utilities']))\n",
    "\n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'Utilities')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'Utilities')\n",
    "\n",
    "    display_colx_coly_scatter(train_nonan_df, 'Utilities', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # Fix - there are houses with \"Other\" set of Utilities. \"Other\" might mean there are no Utilities.\n",
    "    # todo: try replacing with .mode()\n",
    "\n",
    "    train_nonan_df['Utilities'] = train_nonan_df['Utilities'].fillna('Other')\n",
    "    test_nonan_df['Utilities'] = test_nonan_df['Utilities'].fillna('Other')\n",
    "\n",
    "def _local_check():\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'Utilities', 3000))\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'Utilities', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exterior1st and Exterior2nd \n",
    "\n",
    "def _local_disp():\n",
    "    # missing the same row: Id=2152 in test set\n",
    "\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'Exterior1st', 3000))\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'Exterior1st', 3000))\n",
    "\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'Exterior2nd', 3000))\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'Exterior2nd', 3000))\n",
    "\n",
    "    display(pd.unique(train_nonan_df['Exterior1st']))\n",
    "    display(pd.unique(test_nonan_df['Exterior1st']))\n",
    "\n",
    "    display(pd.unique(train_nonan_df['Exterior2nd']))\n",
    "    display(pd.unique(test_nonan_df['Exterior2nd']))\n",
    "\n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'Exterior1st')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'Exterior1st')\n",
    "\n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'Exterior2nd')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'Exterior2nd')\n",
    "\n",
    "    display_colx_coly_scatter(train_nonan_df, 'Exterior1st', 'SalePrice')\n",
    "    display_colx_coly_scatter(train_nonan_df, 'Exterior2nd', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # Fix - assume there might be no exterior at all.\n",
    "\n",
    "    test_nonan_df['Exterior1st'] = test_nonan_df['Exterior1st'].fillna('NoExterior')\n",
    "\n",
    "    test_nonan_df['Exterior2nd'] = test_nonan_df['Exterior2nd'].fillna('NoExterior')\n",
    "\n",
    "def _local_check():\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'Exterior1st', 3000))\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'Exterior1st', 3000))\n",
    "\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'Exterior2nd', 3000))\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'Exterior2nd', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MasVnrType \n",
    "\n",
    "def _local_disp():\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'MasVnrType', 3000))\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'MasVnrType', 3000))\n",
    "\n",
    "    display(pd.unique(train_nonan_df['MasVnrType']))\n",
    "    display(pd.unique(test_nonan_df['MasVnrType']))\n",
    "\n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'MasVnrType')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'MasVnrType')\n",
    "\n",
    "    # NOTE: some points have MasVnrType==None BUT MasVnrArea != 0\n",
    "    display_col_categorical_sns_countplot(train_nonan_df[train_nonan_df['MasVnrType'] == 'None'], 'MasVnrArea')\n",
    "\n",
    "    train_df_cpy = train_nonan_df.copy()\n",
    "    lbl_encoder = LabelEncoder()\n",
    "\n",
    "    train_df_cpy['MasVnrType'] = lbl_encoder.fit_transform(train_df_cpy['MasVnrType'].fillna('None'))\n",
    "    display_colx_coly_scatter(\n",
    "        train_df_cpy,\n",
    "        'MasVnrArea',\n",
    "        'SalePrice',\n",
    "        color='MasVnrType'\n",
    "    )\n",
    "\n",
    "    train_df_cpy['FireplaceQu'] = lbl_encoder.fit_transform(train_df_cpy['FireplaceQu'].fillna('NoQual'))\n",
    "    display_colx_coly_scatter(\n",
    "        train_df_cpy,\n",
    "        'MasVnrArea',\n",
    "        'SalePrice',\n",
    "        color='FireplaceQu'\n",
    "    )\n",
    "    \n",
    "def _local_fix():\n",
    "    # Assume there might be walls with some \"Other\" masonry veneer type.\n",
    "    \n",
    "    train_nonan_df['MasVnrType'] = train_nonan_df['MasVnrType'].fillna('OtherMasVnr')\n",
    "    \n",
    "    test_nonan_df['MasVnrType'] = test_nonan_df['MasVnrType'].fillna('OtherMasVnr')\n",
    "\n",
    "def _local_check():\n",
    "    display(\"train\", get_rows_with_nan(train_nonan_df, 'MasVnrType', 3000))\n",
    "    display(\"test\", get_rows_with_nan(test_nonan_df, 'MasVnrType', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MasVnrArea\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'MasVnrArea', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'MasVnrArea', 3000))\n",
    "    \n",
    "    display_hist(train_nonan_df, 'MasVnrArea', n_bins=100)\n",
    "    display_hist(test_nonan_df, 'MasVnrArea', n_bins=100)\n",
    "    \n",
    "    display_hist(train_nonan_df[train_nonan_df['MasVnrArea'] != 0], 'MasVnrArea', n_bins=100)\n",
    "    display_hist(test_nonan_df[test_nonan_df['MasVnrArea'] != 0], 'MasVnrArea', n_bins=100)\n",
    "    \n",
    "    train_df_cpy = train_nonan_df.copy()\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    train_df_cpy['MasVnrType'] = lbl_encoder.fit_transform(train_df_cpy['MasVnrType'])\n",
    "    display_colx_coly_scatter(train_df_cpy, 'MasVnrArea', 'SalePrice', color='MasVnrType')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume there is no masonvry veneer, so area equals to 0.0\n",
    "    train_nonan_df['MasVnrArea'] = train_nonan_df['MasVnrArea'].fillna(0.0)\n",
    "    test_nonan_df['MasVnrArea'] = test_nonan_df['MasVnrArea'].fillna(0.0)\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'MasVnrArea', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'MasVnrArea', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BsmtQual \n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtQual', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtQual', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtQual', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtQual', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['BsmtQual'].unique())\n",
    "    display(test_nonan_df['BsmtQual'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'BsmtQual')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'BsmtQual')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'BsmtQual', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume there is no basement in the house\n",
    "    \n",
    "    train_nonan_df['BsmtQual'] = train_nonan_df['BsmtQual'].fillna('NoBsmt')\n",
    "    \n",
    "    test_nonan_df['BsmtQual'] = test_nonan_df['BsmtQual'].fillna('NoBsmt')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtQual', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtQual', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BsmtCond\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtCond', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtCond', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtCond', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtCond', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['BsmtCond'].unique())\n",
    "    display(test_nonan_df['BsmtCond'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'BsmtCond')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'BsmtCond')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'BsmtCond', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume there is no basement in the house\n",
    "    \n",
    "    train_nonan_df['BsmtCond'] = train_nonan_df['BsmtCond'].fillna('NoBsmt')\n",
    "    \n",
    "    test_nonan_df['BsmtCond'] = test_nonan_df['BsmtCond'].fillna('NoBsmt')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtCond', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtCond', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BsmtExposure \n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtExposure', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtExposure', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtExposure', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtExposure', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['BsmtExposure'].unique())\n",
    "    display(test_nonan_df['BsmtExposure'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'BsmtExposure')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'BsmtExposure')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'BsmtExposure', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume there is no basement at all\n",
    "    \n",
    "    train_nonan_df['BsmtExposure'] = train_nonan_df['BsmtExposure'].fillna('NoBsmt')\n",
    "    \n",
    "    test_nonan_df['BsmtExposure'] = test_nonan_df['BsmtExposure'].fillna('NoBsmt')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtExposure', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtExposure', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BsmtFinType1 and BsmtFinType2\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinType1', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinType1', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinType1', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinType1', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['BsmtFinType1'].unique())\n",
    "    display(test_nonan_df['BsmtFinType1'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'BsmtFinType1')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'BsmtFinType1')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'BsmtFinType1', 'SalePrice')\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinType2', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinType2', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinType2', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinType2', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['BsmtFinType2'].unique())\n",
    "    display(test_nonan_df['BsmtFinType2'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'BsmtFinType2')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'BsmtFinType2')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'BsmtFinType2', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume there is no basement at all\n",
    "    \n",
    "    train_nonan_df['BsmtFinType1'] = train_nonan_df['BsmtFinType1'].fillna('NoBsmt')    \n",
    "    test_nonan_df['BsmtFinType1'] = test_nonan_df['BsmtFinType1'].fillna('NoBsmt')\n",
    "\n",
    "    train_nonan_df['BsmtFinType2'] = train_nonan_df['BsmtFinType2'].fillna('NoBsmt')    \n",
    "    test_nonan_df['BsmtFinType2'] = test_nonan_df['BsmtFinType2'].fillna('NoBsmt')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinType1', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinType1', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinType2', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinType2', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtFinSF1 and BsmtFinSF2\n",
    "\n",
    "# same idx: id=2121\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinSF1', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinSF1', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinSF1', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinSF1', 3000).shape)\n",
    "    \n",
    "    train_df_cpy = train_nonan_df.copy()\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    train_df_cpy['BsmtFinType1'] = lbl_encoder.fit_transform(train_df_cpy['BsmtFinType1'])\n",
    "    display_colx_coly_scatter(train_df_cpy, 'BsmtFinSF1', 'SalePrice', color='BsmtFinType1')\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinSF2', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinSF2', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinSF2', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinSF2', 3000).shape)\n",
    "    \n",
    "    train_df_cpy['BsmtFinType2'] = lbl_encoder.fit_transform(train_df_cpy['BsmtFinType2'])\n",
    "    display_colx_coly_scatter(train_df_cpy, 'BsmtFinSF2', 'SalePrice', color='BsmtFinType2')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume there is no basement at all\n",
    "    \n",
    "    test_nonan_df['BsmtFinSF1'] = test_nonan_df['BsmtFinSF1'].fillna(0.0)\n",
    "\n",
    "    test_nonan_df['BsmtFinSF2'] = test_nonan_df['BsmtFinSF2'].fillna(0.0)\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinSF1', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinSF1', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFinSF2', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFinSF2', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtUnfSF and TotalBsmtSF\n",
    "\n",
    "# same idx: id=2121\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtUnfSF', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtUnfSF', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtUnfSF', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtUnfSF', 3000).shape)\n",
    "    \n",
    "    train_df_cpy = train_nonan_df.copy()\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    train_df_cpy['BsmtCond'] = lbl_encoder.fit_transform(train_df_cpy['BsmtCond'])\n",
    "    display_colx_coly_scatter(train_df_cpy, 'BsmtUnfSF', 'SalePrice', color='BsmtCond')\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'TotalBsmtSF', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'TotalBsmtSF', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'TotalBsmtSF', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'TotalBsmtSF', 3000).shape)\n",
    "    \n",
    "    display_colx_coly_scatter(train_df_cpy, 'TotalBsmtSF', 'SalePrice', color='BsmtCond')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume there is no basement at all\n",
    "    \n",
    "    test_nonan_df['BsmtUnfSF'] = test_nonan_df['BsmtUnfSF'].fillna(0.0)\n",
    "\n",
    "    test_nonan_df['TotalBsmtSF'] = test_nonan_df['TotalBsmtSF'].fillna(0.0)\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtUnfSF', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtUnfSF', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'TotalBsmtSF', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'TotalBsmtSF', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BsmtFullBath and BsmtHalfBath\n",
    "\n",
    "# same indices: id=2121 and id=2189\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFullBath', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFullBath', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFullBath', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFullBath', 3000).shape)\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'BsmtFullBath')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'BsmtFullBath')\n",
    "\n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'BsmtFullBath', 'SalePrice')\n",
    "        \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtHalfBath', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtHalfBath', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtHalfBath', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtHalfBath', 3000).shape)\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'BsmtHalfBath')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'BsmtHalfBath')\n",
    "\n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'BsmtHalfBath', 'SalePrice')\n",
    "    \n",
    "def _local_fix():\n",
    "    # Assume there is no basement at all => there couldn't be any bath in the basement\n",
    "    \n",
    "    test_nonan_df['BsmtFullBath'] = test_nonan_df['BsmtFullBath'].fillna(0)\n",
    "\n",
    "    test_nonan_df['BsmtHalfBath'] = test_nonan_df['BsmtHalfBath'].fillna(0)\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtFullBath', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtFullBath', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'BsmtHalfBath', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'BsmtHalfBath', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoolQC\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'PoolQC', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'PoolQC', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['PoolQC'].unique())\n",
    "    display(test_nonan_df['PoolQC'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'PoolQC')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'PoolQC')\n",
    "\n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'PoolQC', 'SalePrice')\n",
    "    \n",
    "def _local_fix():\n",
    "    # Assume single missing row belongs to \"Oth\" class, which already exists in train and test sets\n",
    "    \n",
    "    train_nonan_df['PoolQC'] = train_nonan_df['PoolQC'].fillna('NoPool')\n",
    "    \n",
    "    test_nonan_df['PoolQC'] = test_nonan_df['PoolQC'].fillna('NoPool')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'PoolQC', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'PoolQC', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fence\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'Fence', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'Fence', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['Fence'].unique())\n",
    "    display(test_nonan_df['Fence'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'Fence')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'Fence')\n",
    "\n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'Fence', 'SalePrice')\n",
    "    \n",
    "    train_df_cpy = train_nonan_df.copy()\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    train_df_cpy['Fence'] = lbl_encoder.fit_transform(train_df_cpy['Fence'])\n",
    "    display_colx_coly_scatter(train_df_cpy, 'LotArea', 'SalePrice', color='Fence')\n",
    "    \n",
    "def _local_fix():\n",
    "    # Assume single missing row belongs to \"Oth\" class, which already exists in train and test sets\n",
    "    \n",
    "    train_nonan_df['Fence'] = train_nonan_df['Fence'].fillna('NoFence')\n",
    "    \n",
    "    test_nonan_df['Fence'] = test_nonan_df['Fence'].fillna('NoFence')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'Fence', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'Fence', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MiscFeature\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'MiscFeature', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'MiscFeature', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['MiscFeature'].unique())\n",
    "    display(test_nonan_df['MiscFeature'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'MiscFeature')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'MiscFeature')\n",
    "\n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'MiscFeature', 'SalePrice')\n",
    "    \n",
    "    display_colx_coly_scatter(\n",
    "        train_nonan_df[train_nonan_df['MiscFeature'] == 'Shed'], 'MiscFeature', 'SalePrice'\n",
    "    )\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume single missing row belongs to \"Oth\" class, which already exists in train and test sets\n",
    "    \n",
    "    train_nonan_df['MiscFeature'] = train_nonan_df['MiscFeature'].fillna('None')\n",
    "    \n",
    "    test_nonan_df['MiscFeature'] = test_nonan_df['MiscFeature'].fillna('None')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'MiscFeature', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'MiscFeature', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SaleType \n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'SaleType', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'SaleType', 3000))\n",
    "    \n",
    "    display(train_nonan_df['SaleType'].unique())\n",
    "    display(test_nonan_df['SaleType'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'SaleType')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'SaleType')\n",
    "    \n",
    "    train_df_cpy = train_nonan_df.copy()\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    train_df_cpy['SaleCondition'] = lbl_encoder.fit_transform(train_df_cpy['SaleCondition'])\n",
    "    display_colx_coly_scatter(train_df_cpy, 'SaleType', 'SalePrice', color='SaleCondition')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume single missing row belongs to \"Oth\" class, which already exists in train and test sets\n",
    "    \n",
    "    train_nonan_df['SaleType'] = train_nonan_df['SaleType'].fillna('Oth')\n",
    "    \n",
    "    test_nonan_df['SaleType'] = test_nonan_df['SaleType'].fillna('Oth')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'SaleType', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'SaleType', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FireplaceQu\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'FireplaceQu', 3000).head(3))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'FireplaceQu', 3000).head(3))\n",
    "\n",
    "    display(get_rows_with_nan(train_nonan_df, 'FireplaceQu', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'FireplaceQu', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['FireplaceQu'].unique())\n",
    "    display(test_nonan_df['FireplaceQu'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'FireplaceQu')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'FireplaceQu')\n",
    "    \n",
    "    train_fireplaces_nan = get_rows_with_nan(train_nonan_df, 'FireplaceQu', 3000)\n",
    "    display(train_fireplaces_nan[train_fireplaces_nan['Fireplaces'] != 0])  # empty df\n",
    "    \n",
    "    test_fireplaces_nan = get_rows_with_nan(test_nonan_df, 'FireplaceQu', 3000)\n",
    "    display(test_fireplaces_nan[test_fireplaces_nan['Fireplaces'] != 0])  # empty df\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'SaleType', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume there is no fireplace at all (because \"Fireplaces\" = 0)\n",
    "    \n",
    "    train_nonan_df['FireplaceQu'] = train_nonan_df['FireplaceQu'].fillna('None')\n",
    "    \n",
    "    test_nonan_df['FireplaceQu'] = test_nonan_df['FireplaceQu'].fillna('None')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'FireplaceQu', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'FireplaceQu', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other features with NaN values: Electrical, KitchenQual, Functional\n",
    "\n",
    "# Electrical: train_nonan_df, row id=1380\n",
    "# KitchenQual: test_nonan_df, row_id=1556\n",
    "# Functional: test_nona_df, row_indices=2217,2474.\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'Electrical', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'Electrical', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'KitchenQual', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'KitchenQual', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'Functional', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'Functional', 3000))\n",
    "    \n",
    "def _local_fix():\n",
    "    # Electrical: replace with the most common value\n",
    "    train_nonan_df['Electrical'] = train_nonan_df['Electrical'].fillna(\n",
    "        train_nonan_df['Electrical'].mode()[0]\n",
    "    )\n",
    "    # KitchenQual: replace with the most common value\n",
    "    test_nonan_df['KitchenQual'] = test_nonan_df['KitchenQual'].fillna(\n",
    "        test_nonan_df['KitchenQual'].mode()[0]\n",
    "    )\n",
    "    # Functional: from docs: \"Assume typical unless deductions are warranted\"\n",
    "    test_nonan_df['Functional'] = test_nonan_df['Functional'].fillna('Typ')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'Electrical', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'Electrical', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'KitchenQual', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'KitchenQual', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'Functional', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'Functional', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GarageType\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageType', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageType', 3000))\n",
    "\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageType', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageType', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['GarageType'].unique())\n",
    "    display(test_nonan_df['GarageType'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'GarageType')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'GarageType')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'GarageType', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # Assume there is no garage (because all GarageArea==0.0)\n",
    "    \n",
    "    train_nonan_df['GarageType'] = train_nonan_df['GarageType'].fillna('NoGarage')\n",
    "    \n",
    "    test_nonan_df['GarageType'] = test_nonan_df['GarageType'].fillna('NoGarage')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageType', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageType', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GarageYrBlt\n",
    "\n",
    "def _local_disp():\n",
    "#     display(get_rows_with_nan(train_nonan_df, 'GarageYrBlt', 3000))\n",
    "#     display(get_rows_with_nan(test_nonan_df, 'GarageYrBlt', 3000))\n",
    "\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageYrBlt', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageYrBlt', 3000).shape)\n",
    "    \n",
    "    train_nan_garageyrblt = get_rows_with_nan(train_nonan_df, 'GarageYrBlt', 3000)\n",
    "    display(train_nan_garageyrblt[train_nan_garageyrblt['GarageType'] == 'Detchd'])  # empty\n",
    "    \n",
    "    test_nan_garageyrblt = get_rows_with_nan(test_nonan_df, 'GarageYrBlt', 3000)\n",
    "    display(test_nan_garageyrblt[test_nan_garageyrblt['GarageType'] == 'Detchd'])  # indices=[2127,2577]\n",
    "    \n",
    "    display(train_nonan_df['GarageYrBlt'].min(), train_nonan_df['GarageYrBlt'].max())\n",
    "    display(test_nonan_df['GarageYrBlt'].min(), test_nonan_df['GarageYrBlt'].max())\n",
    "    \n",
    "    display_hist(train_nonan_df, 'GarageYrBlt', n_bins=100)\n",
    "    display_hist(test_nonan_df, 'GarageYrBlt', n_bins=100)\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df, 'GarageYrBlt', 'SalePrice')\n",
    "    \n",
    "def _local_fix():\n",
    "    # For indices=[2127,2577]: because they are detached -> replace by median value\n",
    "    dtchd_garage_yrblt_median = test_nonan_df.groupby('GarageType').get_group('Detchd')['GarageYrBlt'].median()\n",
    "    test_nonan_df.loc[666, 'GarageYrBlt'] = dtchd_garage_yrblt_median\n",
    "    test_nonan_df.loc[1116, 'GarageYrBlt'] = dtchd_garage_yrblt_median\n",
    "    \n",
    "    # Assume all other rows with NaN in GarageYrBlt mean that there is no garage at all    \n",
    "    # Because GarageYrBlt is a numerical feature, replace it with a really early year - 1500 - \"Magic year\".\n",
    "    # This feature will be \"cut\" later so no worry for such an inadequate value.\n",
    "    \n",
    "    train_nonan_df['GarageYrBlt'] = train_nonan_df['GarageYrBlt'].fillna(1500)\n",
    "    \n",
    "    test_nonan_df['GarageYrBlt'] = test_nonan_df['GarageYrBlt'].fillna(1500)\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageYrBlt', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageYrBlt', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GarageFinish\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageFinish', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageFinish', 3000))\n",
    "\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageFinish', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageFinish', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['GarageFinish'].unique())\n",
    "    display(test_nonan_df['GarageFinish'].unique())\n",
    "    \n",
    "    train_nan_garageyrblt = get_rows_with_nan(train_nonan_df, 'GarageFinish', 3000)\n",
    "    display(train_nan_garageyrblt[train_nan_garageyrblt['GarageType'] == 'Detchd'])  # empty\n",
    "    \n",
    "    test_nan_garageyrblt = get_rows_with_nan(test_nonan_df, 'GarageFinish', 3000)\n",
    "    display(test_nan_garageyrblt[test_nan_garageyrblt['GarageType'] == 'Detchd'])  # indices=[2127,2577]\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'GarageFinish')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'GarageFinish')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'GarageFinish', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # For indices=[2127,2577]: because they are detached -> replace by median value\n",
    "    dtchd_garage_garagefinish_mode = test_nonan_df.groupby('GarageType'\n",
    "                                                          ).get_group('Detchd')['GarageFinish'].mode()[0]\n",
    "    test_nonan_df.loc[666, 'GarageFinish'] = dtchd_garage_garagefinish_mode\n",
    "    test_nonan_df.loc[1116, 'GarageFinish'] = dtchd_garage_garagefinish_mode\n",
    "\n",
    "    # Assume all other rows with NaN in GarageFinish mean that there is no garage at all\n",
    "    # Another reason: in these rows GarageArea == 0 => there is no garage at all\n",
    "        \n",
    "    train_nonan_df['GarageFinish'] = train_nonan_df['GarageFinish'].fillna('NoGarage')\n",
    "    \n",
    "    test_nonan_df['GarageFinish'] = test_nonan_df['GarageFinish'].fillna('NoGarage')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageFinish', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageFinish', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GarageCars and GarageArea\n",
    "\n",
    "# 1 row: id=2577\n",
    "\n",
    "def _local_disp():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageCars', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageCars', 3000))\n",
    "\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageCars', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageCars', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['GarageCars'].unique())\n",
    "    display(test_nonan_df['GarageCars'].unique())\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'GarageCars')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'GarageCars')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'GarageCars', 'SalePrice')\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageArea', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageArea', 3000))\n",
    "\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageArea', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageArea', 3000).shape)\n",
    "    \n",
    "    display_hist(train_nonan_df, 'GarageArea', n_bins=100)\n",
    "    display_hist(test_nonan_df, 'GarageArea', n_bins=100)\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'GarageArea', 'SalePrice', color='GarageCars')\n",
    "\n",
    "def _local_fix():\n",
    "    # GarageCars\n",
    "    # For idx=[2577]: because garagetype is detached -> replace by mode value\n",
    "    test_nonan_df.loc[1116, 'GarageCars'\n",
    "                     ] = test_nonan_df.groupby('GarageType').get_group('Detchd')['GarageCars'].median()\n",
    "\n",
    "    # GarageArea\n",
    "    # For idx=[2577]: because garagetype is detached -> replace by mode value\n",
    "    test_nonan_df.loc[1116, 'GarageArea'\n",
    "                     ] = test_nonan_df.groupby('GarageType').get_group('Detchd')['GarageArea'].mean()\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageCars', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageCars', 3000))\n",
    "    \n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageArea', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageArea', 3000))\n",
    "    \n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GarageQual\n",
    "\n",
    "def _local_disp():\n",
    "#     display(get_rows_with_nan(train_nonan_df, 'GarageQual', 3000))\n",
    "#     display(get_rows_with_nan(test_nonan_df, 'GarageQual', 3000))\n",
    "\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageQual', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageQual', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['GarageQual'].unique())\n",
    "    display(test_nonan_df['GarageQual'].unique())\n",
    "    \n",
    "    train_nan_garageyrblt = get_rows_with_nan(train_nonan_df, 'GarageQual', 3000)\n",
    "    display(train_nan_garageyrblt[train_nan_garageyrblt['GarageType'] == 'Detchd'])  # empty\n",
    "    \n",
    "    test_nan_garageyrblt = get_rows_with_nan(test_nonan_df, 'GarageQual', 3000)\n",
    "    display(test_nan_garageyrblt[test_nan_garageyrblt['GarageType'] == 'Detchd'])  # indices=[2127,2577]\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'GarageQual')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'GarageQual')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'GarageQual', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # For indices=[2127,2577]: because they are detached -> replace by median value\n",
    "    dtchd_garage_garagefinish_mode = test_nonan_df.groupby('GarageType'\n",
    "                                                          ).get_group('Detchd')['GarageQual'].mode()[0]\n",
    "    test_nonan_df.loc[666, 'GarageQual'] = dtchd_garage_garagefinish_mode\n",
    "    test_nonan_df.loc[1116, 'GarageQual'] = dtchd_garage_garagefinish_mode\n",
    "\n",
    "    # For every other garagetype=np.nan: assume there is no garage at all\n",
    "    \n",
    "    train_nonan_df['GarageQual'] = train_nonan_df['GarageQual'].fillna('NoGarage')\n",
    "    \n",
    "    test_nonan_df['GarageQual'] = test_nonan_df['GarageQual'].fillna('NoGarage')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageQual', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageQual', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GarageCond\n",
    "\n",
    "def _local_disp():\n",
    "#     display(get_rows_with_nan(train_nonan_df, 'GarageQual', 3000))\n",
    "#     display(get_rows_with_nan(test_nonan_df, 'GarageQual', 3000))\n",
    "\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageCond', 3000).shape)\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageCond', 3000).shape)\n",
    "    \n",
    "    display(train_nonan_df['GarageCond'].unique())\n",
    "    display(test_nonan_df['GarageCond'].unique())\n",
    "    \n",
    "    train_nan_garageyrblt = get_rows_with_nan(train_nonan_df, 'GarageCond', 3000)\n",
    "    display(train_nan_garageyrblt[train_nan_garageyrblt['GarageType'] == 'Detchd'])  # empty\n",
    "    \n",
    "    test_nan_garageyrblt = get_rows_with_nan(test_nonan_df, 'GarageCond', 3000)\n",
    "    display(test_nan_garageyrblt[test_nan_garageyrblt['GarageType'] == 'Detchd'])  # indices=[2127,2577]\n",
    "    \n",
    "    display_col_categorical_sns_countplot(train_nonan_df, 'GarageCond')\n",
    "    display_col_categorical_sns_countplot(test_nonan_df, 'GarageCond')\n",
    "    \n",
    "    display_colx_coly_scatter(train_nonan_df.fillna('dbg'), 'GarageCond', 'SalePrice')\n",
    "\n",
    "def _local_fix():\n",
    "    # For indices=[2127,2577]: because they are detached -> replace by median value\n",
    "    dtchd_garage_garagefinish_mode = test_nonan_df.groupby('GarageType'\n",
    "                                                          ).get_group('Detchd')['GarageCond'].mode()[0]\n",
    "    test_nonan_df.loc[666, 'GarageCond'] = dtchd_garage_garagefinish_mode\n",
    "    test_nonan_df.loc[1116, 'GarageCond'] = dtchd_garage_garagefinish_mode\n",
    "\n",
    "    # For every other GarageCond=np.nan: assume there is no garage at all\n",
    "    \n",
    "    train_nonan_df['GarageCond'] = train_nonan_df['GarageCond'].fillna('NoGarage')\n",
    "    \n",
    "    test_nonan_df['GarageCond'] = test_nonan_df['GarageCond'].fillna('NoGarage')\n",
    "\n",
    "def _local_check():\n",
    "    display(get_rows_with_nan(train_nonan_df, 'GarageCond', 3000))\n",
    "    display(get_rows_with_nan(test_nonan_df, 'GarageCond', 3000))\n",
    "\n",
    "# Explore\n",
    "# _local_disp()\n",
    "\n",
    "# Fix\n",
    "_local_fix()\n",
    "\n",
    "# Check\n",
    "# _local_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check again fixed NaN values\n",
    "\n",
    "display_nan_values(train_nonan_df)\n",
    "\n",
    "display_nan_values(test_nonan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to fix column dtypes\n",
    "\n",
    "# Divide continuous data into n_bins bins.\n",
    "def continuous_to_bins_inplace(dataset_df, col_name, n_bins):\n",
    "    qcut_bins = pd.qcut(dataset_df[col_name], n_bins, retbins=True)[1]\n",
    "    qcut_bins[0] = int(qcut_bins[0]) - 1\n",
    "    qcut_bins[-1] = int(qcut_bins[-1]) + 2\n",
    "    column_copy = dataset_df[col_name].copy()\n",
    "    for idx in range(len(qcut_bins) - 1):\n",
    "        cur_range_start = qcut_bins[idx]\n",
    "        cur_range_end = qcut_bins[idx + 1]\n",
    "        after_start_mask = column_copy >= cur_range_start \n",
    "        before_end_mask = column_copy < cur_range_end\n",
    "        dataset_df.loc[\n",
    "            after_start_mask & before_end_mask, col_name\n",
    "        ] = \"{0}_{1}\".format(cur_range_start, cur_range_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate arrays\n",
    "\n",
    "train_fixdtypes_df = train_nonan_df.copy()\n",
    "test_fixdtypes_df = test_nonan_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_dataset_col_dtypes(train_nonan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix several features from numerical to categorical dtype\n",
    "\n",
    "num2cat_col_names = [\n",
    "    'MSSubClass',\n",
    "    'OverallQual', 'OverallCond',\n",
    "    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "    'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
    "    'Fireplaces',\n",
    "    'GarageCars',\n",
    "    'MoSold', 'YrSold'\n",
    "]\n",
    "\n",
    "for col_name in num2cat_col_names:\n",
    "    train_fixdtypes_df[col_name] = train_fixdtypes_df[col_name].astype(str)\n",
    "    test_fixdtypes_df[col_name] = test_fixdtypes_df[col_name].astype(str)\n",
    "    \n",
    "# Cut several features into different chunks\n",
    "\n",
    "# YearRemodAdd\n",
    "continuous_to_bins_inplace(train_fixdtypes_df, 'YearRemodAdd', 4)\n",
    "continuous_to_bins_inplace(test_fixdtypes_df, 'YearRemodAdd', 4)\n",
    "\n",
    "# YearBuilt\n",
    "continuous_to_bins_inplace(train_fixdtypes_df, 'YearBuilt', 4)\n",
    "continuous_to_bins_inplace(test_fixdtypes_df, 'YearBuilt', 4)\n",
    "\n",
    "# GarageYrBlt\n",
    "def _ugly_fix_garageyrblt_categories_inplace(dataset_df):\n",
    "    garageyrblt_cpy = dataset_df['GarageYrBlt']\n",
    "    dataset_df.loc[(garageyrblt_cpy == 1500), 'GarageYrBlt'] = \"0\"\n",
    "    dataset_df.loc[(garageyrblt_cpy >= 1899.0 - 1) & (garageyrblt_cpy < 1961.0), 'GarageYrBlt'] = \"1\"\n",
    "    dataset_df.loc[(garageyrblt_cpy >= 1961.0 - 1) & (garageyrblt_cpy < 1980.0), 'GarageYrBlt'] = \"2\"\n",
    "    dataset_df.loc[(garageyrblt_cpy >= 1980.0 - 1) & (garageyrblt_cpy < 2002.0), 'GarageYrBlt'] = \"3\"\n",
    "    dataset_df.loc[(garageyrblt_cpy >= 2002.0 - 1) & (garageyrblt_cpy < 2012.0 + 2), 'GarageYrBlt'] = \"4\"\n",
    "_ugly_fix_garageyrblt_categories_inplace(train_fixdtypes_df)\n",
    "_ugly_fix_garageyrblt_categories_inplace(test_fixdtypes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_dataset_col_dtypes(train_fixdtypes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to try out models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out models for data \"without nan; fixed dtypes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide concat_train_test_df into train and test parts\n",
    "\n",
    "X_train_full = concat_train_test_df[:train_df.shape[0]].drop('Id', axis=1)\n",
    "\n",
    "X_train = X_train_full.drop('SalePrice', axis=1)\n",
    "y_train = X_train_full['SalePrice']\n",
    "\n",
    "X_test = concat_train_test_df[train_df.shape[0]:].drop(['SalePrice', 'Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical values with LabelEncoder\n",
    "\n",
    "def encode_column_inplace(dataset_df, col_name):\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    dataset_df[col_name] = lbl_encoder.fit_transform(dataset_df[col_name].values)\n",
    "    \n",
    "categorical_columns = concat_train_test_df.select_dtypes(include='object').columns.values    \n",
    "\n",
    "for col_name in categorical_columns:\n",
    "    encode_column_inplace(X_train, col_name)\n",
    "    encode_column_inplace(X_test, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out different regressors for raw data (fixed np.nan and encoded labels)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_folds = KFold(n_splits=10)\n",
    "\n",
    "models = [\n",
    "    LassoCV(), RidgeCV(), LinearRegression(), ElasticNetCV(cv=n_folds), BayesianRidge(),\n",
    "    KNeighborsRegressor(), \n",
    "    RandomForestRegressor(), GradientBoostingRegressor(),\n",
    "    XGBRegressor(objective='reg:squarederror'),\n",
    "    SVR(kernel='rbf', gamma=0.1)\n",
    "]\n",
    "\n",
    "print(\"score by cross-validation, k=10, train:\")\n",
    "for model in models:\n",
    "    print(cross_val_score(model, X_train, y_train, cv=n_folds).mean())\n",
    "    \n",
    "pre_X_train, pre_X_test, pre_y_train, pre_y_test = train_test_split(\n",
    "    X_train, y_train, random_state=42\n",
    ")\n",
    "\n",
    "print(\"r2:\")\n",
    "for model in models:\n",
    "    model.fit(pre_X_train, pre_y_train)\n",
    "    pre_y_pred = model.predict(pre_X_test)\n",
    "    print(r2_score(pre_y_test, pre_y_pred))\n",
    "    \n",
    "print(\"rmsle:\")\n",
    "for model in models:\n",
    "    model.fit(pre_X_train, pre_y_train)\n",
    "    pre_y_pred = model.predict(pre_X_test)\n",
    "    print(np.sqrt(mean_squared_log_error(pre_y_test, pre_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairplot for continuous data\n",
    "\n",
    "continous_columns = concat_train_test_df.select_dtypes(include='number').columns.values\n",
    "display(continous_columns)\n",
    "\n",
    "# sns.pairplot(concat_train_test_df.loc[:, continous_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing outliers\n",
    "\n",
    "# Use sns.pairplot saved image to get depdencies for SalePrice for continuous data\n",
    "\n",
    "X_train_full_nooutliers = X_train.copy()\n",
    "X_train_full_nooutliers['SalePrice'] = y_train\n",
    "\n",
    "display(\"Before removing outliers, shape\", X_train_full_nooutliers.shape)\n",
    "\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[\n",
    "        (X_train_full_nooutliers['GrLivArea'] > 4000) & (X_train_full_nooutliers['SalePrice'] < 200000)\n",
    "    ].index\n",
    ")\n",
    "\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[X_train_full_nooutliers['LotFrontage'] > 250].index\n",
    ")\n",
    "\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[X_train_full_nooutliers['LotArea'] > 50000].index\n",
    ")\n",
    "\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[X_train_full_nooutliers['MasVnrArea'] > 1200].index\n",
    ")\n",
    "\n",
    "display_col_saleprice_scplot(X_train_full_nooutliers, 'BsmtFinSF2')\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[X_train_full_nooutliers['BsmtFinSF2'] > 1400].index\n",
    ")\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[\n",
    "        (X_train_full_nooutliers['BsmtFinSF2'] > 150) & \n",
    "        (X_train_full_nooutliers['BsmtFinSF2'] < 600) &\n",
    "        (X_train_full_nooutliers['SalePrice'] > 350000)\n",
    "    ].index\n",
    ")\n",
    "display_col_saleprice_scplot(X_train_full_nooutliers, 'BsmtFinSF2')\n",
    "\n",
    "\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[X_train_full_nooutliers['TotalBsmtSF'] > 3000].index\n",
    ")\n",
    "\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[\n",
    "        (X_train_full_nooutliers['GarageArea'] > 1200) & \n",
    "        (X_train_full_nooutliers['SalePrice'] < 300000)\n",
    "    ].index\n",
    ")\n",
    "\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[X_train_full_nooutliers['OpenPorchSF'] > 400].index\n",
    ")\n",
    "\n",
    "X_train_full_nooutliers = X_train_full_nooutliers.drop(\n",
    "    X_train_full_nooutliers[X_train_full_nooutliers['EnclosedPorch'] > 400].index\n",
    ")\n",
    "\n",
    "display(\"After removing outliers, shape\", X_train_full_nooutliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try same initial models with removed outliers\n",
    "\n",
    "X_train_nooutliers = X_train_full_nooutliers.drop('SalePrice', axis=1)\n",
    "y_train_nooutliers = X_train_full_nooutliers['SalePrice']\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_folds = KFold(n_splits=10)\n",
    "\n",
    "models = [\n",
    "    LassoCV(), RidgeCV(), LinearRegression(), ElasticNetCV(cv=n_folds), BayesianRidge(),\n",
    "    KNeighborsRegressor(), \n",
    "    RandomForestRegressor(), GradientBoostingRegressor(),\n",
    "    XGBRegressor(objective='reg:squarederror'),\n",
    "    SVR(kernel='rbf', gamma=0.1)\n",
    "]\n",
    "\n",
    "print(\"score by cross-validation, k=10, train:\")\n",
    "for model in models:\n",
    "    print(cross_val_score(model, X_train_nooutliers, y_train_nooutliers, cv=n_folds).mean())\n",
    "    \n",
    "outl_X_train, outl_X_test, outl_y_train, outl_y_test = train_test_split(\n",
    "    X_train_nooutliers, y_train_nooutliers, random_state=42\n",
    ")\n",
    "\n",
    "print(\"r2:\")\n",
    "for model in models:\n",
    "    model.fit(outl_X_train, outl_y_train)\n",
    "    outl_y_pred = model.predict(outl_X_test)\n",
    "    print(r2_score(outl_y_test, outl_y_pred))\n",
    "    \n",
    "print(\"rmsle:\")\n",
    "for model in models:\n",
    "    model.fit(outl_X_train, outl_y_train)\n",
    "    outl_y_pred = model.predict(outl_X_test)\n",
    "    print(np.sqrt(mean_squared_log_error(outl_y_test, outl_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skew continuous data to normal distribution\n",
    "\n",
    "def display_df_numerical_before_after_log(dataset_df, col_name):\n",
    "    fig, [ax_0, ax_1, ax_2, ax_3] = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    sns.distplot(dataset_df[col_name], ax=ax_0)\n",
    "    sns.distplot(np.log(dataset_df[col_name]), ax=ax_1)\n",
    "    stats.probplot(dataset_df[col_name], plot=ax_2)\n",
    "    stats.probplot(np.log(dataset_df[col_name]), plot=ax_3)\n",
    "    plt.show()\n",
    "    \n",
    "fig, [ax_0, ax_1, ax_2, ax_3] = plt.subplots(1, 4, figsize=(15, 5))\n",
    "sns.distplot(y_train_nooutliers, ax=ax_0)\n",
    "sns.distplot(np.log(y_train_nooutliers), ax=ax_1)\n",
    "stats.probplot(y_train_nooutliers, plot=ax_2)\n",
    "stats.probplot(np.log(y_train_nooutliers), plot=ax_3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "numerical_columns_to_skew = ['LotArea', '1stFlrSF', 'GrLivArea']\n",
    "\n",
    "for col_name in numerical_columns_to_skew:\n",
    "    display_df_numerical_before_after_log(X_train_full_nooutliers, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix skewiness\n",
    "\n",
    "X_train_noskew = X_train_nooutliers.copy()\n",
    "for col_name in numerical_columns_to_skew:\n",
    "    X_train_noskew[col_name] = np.log(X_train_noskew[col_name])\n",
    "y_train_noskew = np.log(y_train_nooutliers)\n",
    "\n",
    "X_test_noskew = X_test.copy()\n",
    "for col_name in numerical_columns_to_skew:\n",
    "    X_test_noskew[col_name] = np.log(X_test_noskew[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Explore skewed data\n",
    "\n",
    "# Distplots: before-after\n",
    "sns.pairplot(X_train_nooutliers.loc[:, numerical_columns_to_skew]); plt.show()\n",
    "sns.pairplot(X_train_noskew.loc[:, numerical_columns_to_skew]); plt.show()\n",
    "\n",
    "# Pearson correlation: before-after\n",
    "sns.heatmap(X_train_nooutliers.loc[:, numerical_columns_to_skew].corr(), annot=True); plt.show()\n",
    "sns.heatmap(X_train_noskew.loc[:, numerical_columns_to_skew].corr(), annot=True); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try initial models with fixed skewed data and removed outliers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_folds = KFold(n_splits=10)\n",
    "\n",
    "models = [\n",
    "    LassoCV(), RidgeCV(), LinearRegression(), ElasticNetCV(cv=n_folds), BayesianRidge(),\n",
    "    KNeighborsRegressor(), \n",
    "    RandomForestRegressor(), GradientBoostingRegressor(),\n",
    "    XGBRegressor(objective='reg:squarederror'),\n",
    "    SVR(kernel='rbf', gamma=0.1)\n",
    "]\n",
    "\n",
    "print(\"score by cross-validation, k=10, train:\")\n",
    "for model in models:\n",
    "    print(cross_val_score(model, X_train_noskew, y_train_noskew, cv=n_folds).mean())\n",
    "    \n",
    "nosk_X_train, nosk_X_test, nosk_y_train, nosk_y_test = train_test_split(\n",
    "    X_train_noskew, y_train_noskew, random_state=42\n",
    ")\n",
    "\n",
    "print(\"r2:\")\n",
    "for model in models:\n",
    "    model.fit(nosk_X_train, nosk_y_train)\n",
    "    nosk_y_pred = model.predict(nosk_X_test)\n",
    "    print(r2_score(nosk_y_test, nosk_y_pred))\n",
    "    \n",
    "print(\"rmsle:\")\n",
    "for model in models:\n",
    "    model.fit(nosk_X_train, nosk_y_train)\n",
    "    nosk_y_pred = model.predict(nosk_X_test)\n",
    "    print(np.sqrt(mean_squared_error(nosk_y_test, nosk_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "concat_train_test_noskew_df = pd.concat([X_train_noskew, X_test_noskew], ignore_index=True, sort=False)\n",
    "\n",
    "continuous_to_bins_inplace(concat_train_test_noskew_df, 'BsmtFinSF1', 10)\n",
    "\n",
    "concat_train_test_noskew_df['BsmtFinSF2_Flag'] = concat_train_test_noskew_df['BsmtFinSF2'].map(\n",
    "    lambda x: 0 if x==0 else 1\n",
    ")\n",
    "concat_train_test_noskew_df = concat_train_test_noskew_df.drop('BsmtFinSF2', axis=1)\n",
    "\n",
    "continuous_to_bins_inplace(concat_train_test_noskew_df, 'BsmtUnfSF', 20)\n",
    "\n",
    "continuous_to_bins_inplace(concat_train_test_noskew_df, 'TotalBsmtSF', 20)\n",
    "\n",
    "continuous_to_bins_inplace(concat_train_test_noskew_df, '1stFlrSF', 20)\n",
    "\n",
    "continuous_to_bins_inplace(concat_train_test_noskew_df, '2ndFlrSF', 20)\n",
    "\n",
    "concat_train_test_noskew_df['LowQualFinSF_Flag'] = concat_train_test_noskew_df['LowQualFinSF'].map(\n",
    "    lambda x: 0 if x==0 else 1\n",
    ")\n",
    "concat_train_test_noskew_df = concat_train_test_noskew_df.drop('LowQualFinSF', axis=1)\n",
    "\n",
    "concat_train_test_noskew_df['TotalBathrooms'] = \\\n",
    "    concat_train_test_noskew_df['HalfBath'] + concat_train_test_noskew_df['FullBath'] + \\\n",
    "    concat_train_test_noskew_df['BsmtHalfBath'] + concat_train_test_noskew_df['BsmtFullBath']\n",
    "bathroom_columns = ['HalfBath', 'FullBath', 'BsmtHalfBath', 'BsmtFullBath']\n",
    "concat_train_test_noskew_df = concat_train_test_noskew_df.drop(bathroom_columns, axis=1)\n",
    "\n",
    "continuous_to_bins_inplace(concat_train_test_noskew_df, 'GrLivArea', 20)\n",
    "\n",
    "concat_train_test_noskew_df['MasVnrArea_Flag'] = concat_train_test_noskew_df['MasVnrArea'].map(\n",
    "    lambda x: 0 if x==0 else 1\n",
    ")\n",
    "concat_train_test_noskew_df = concat_train_test_noskew_df.drop('MasVnrArea', axis=1)\n",
    "\n",
    "continuous_to_bins_inplace(concat_train_test_noskew_df, 'GarageArea', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try initial models after feature engineering and fixing skewing steps\n",
    "\n",
    "X_train_feateng = concat_train_test_noskew_df[:X_train_noskew.shape[0]]\n",
    "y_train_feateng = y_train_noskew.copy()\n",
    "X_test_feateng = concat_train_test_noskew_df[X_train_noskew.shape[0]:]\n",
    "\n",
    "# Prepare test sets for noskew and featureeng concat dataset\n",
    "noskew_new_categorical_columns = concat_train_test_noskew_df.select_dtypes(include='object').columns.values\n",
    "\n",
    "for col_name in noskew_new_categorical_columns:\n",
    "    encode_column_inplace(X_train_feateng, col_name)\n",
    "    encode_column_inplace(X_test_feateng, col_name)\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_folds = KFold(n_splits=10)\n",
    "\n",
    "models = [\n",
    "    LassoCV(), RidgeCV(), LinearRegression(), ElasticNetCV(cv=n_folds), BayesianRidge(),\n",
    "    KNeighborsRegressor(), \n",
    "    RandomForestRegressor(), GradientBoostingRegressor(),\n",
    "    XGBRegressor(objective='reg:squarederror'),\n",
    "    SVR(kernel='rbf', gamma=0.1)\n",
    "]\n",
    "\n",
    "print(\"score by cross-validation, k=10, train:\")\n",
    "for model in models:\n",
    "    print(cross_val_score(model, X_train_feateng, y_train_feateng, cv=n_folds).mean())\n",
    "    \n",
    "feateng_X_train, feateng_X_test, feateng_y_train, feateng_y_test = train_test_split(\n",
    "    X_train_feateng, y_train_feateng, random_state=42\n",
    ")\n",
    "\n",
    "print(\"r2:\")\n",
    "for model in models:\n",
    "    model.fit(feateng_X_train, feateng_y_train)\n",
    "    feateng_y_pred = model.predict(feateng_X_test)\n",
    "    print(r2_score(feateng_y_test, feateng_y_pred))\n",
    "    \n",
    "print(\"rmsle:\")\n",
    "for model in models:\n",
    "    model.fit(feateng_X_train, feateng_y_train)\n",
    "    feateng_y_pred = model.predict(feateng_X_test)\n",
    "    print(np.sqrt(mean_squared_error(feateng_y_test, feateng_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "\n",
    "X_train_feateng_full = X_train_feateng.copy()\n",
    "X_train_feateng_full['SalePrice'] = y_train_feateng\n",
    "\n",
    "# Pearson correlation for numerical data\n",
    "display(X_train_feateng_full.corr().abs().loc[:, 'SalePrice'].sort_values())\n",
    "\n",
    "# features_to_remove = X_train_feateng_full.corr().abs().loc[:, 'SalePrice'].sort_values()[:20].index\n",
    "# display(features_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Feature importances: RandomForestRegressor\n",
    "\n",
    "model_rfr = RandomForestRegressor()\n",
    "model_rfr.fit(X_train_feateng, y_train_feateng)\n",
    "\n",
    "display(model_rfr.feature_importances_)\n",
    "\n",
    "importances_df = pd.DataFrame({'importance': model_rfr.feature_importances_})\n",
    "importances_df['feature'] = X_train_feateng.columns\n",
    "importances_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "importances_df = importances_df.set_index('feature', drop=True)\n",
    "importances_df.plot.barh()\n",
    "plt.show()\n",
    "\n",
    "importances_df_top = importances_df.iloc[:20, :]\n",
    "importances_df_top.plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances: XGBRegressor\n",
    "\n",
    "model_xgbr = XGBRegressor()\n",
    "model_xgbr.fit(X_train_feateng, y_train_feateng)\n",
    "\n",
    "importances_df = pd.DataFrame({'importance': model_xgbr.feature_importances_})\n",
    "importances_df['feature'] = X_train_feateng.columns\n",
    "importances_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "importances_df = importances_df.set_index('feature', drop=True)\n",
    "importances_df.plot.barh()\n",
    "plt.show()\n",
    "\n",
    "importances_df_top = importances_df.iloc[:20, :]\n",
    "importances_df_top.plot.barh()\n",
    "plt.show()\n",
    "\n",
    "display(importances_df_top.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try removing features with default models\n",
    "\n",
    "features_to_drop = importances_df.iloc[50:, :].index.values\n",
    "\n",
    "X_train_remfeat = X_train_feateng.drop(features_to_drop, axis=1)\n",
    "X_test_remfeat = X_test_feateng.drop(features_to_drop, axis=1)\n",
    "y_train_remfeat = y_train_feateng.copy()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_folds = KFold(n_splits=10)\n",
    "\n",
    "models = [\n",
    "    LassoCV(), RidgeCV(), LinearRegression(), ElasticNetCV(cv=n_folds), BayesianRidge(),\n",
    "    KNeighborsRegressor(), \n",
    "    RandomForestRegressor(), GradientBoostingRegressor(),\n",
    "    XGBRegressor(objective='reg:squarederror'),\n",
    "    SVR(kernel='rbf', gamma=0.1)\n",
    "]\n",
    "\n",
    "print(\"score by cross-validation, k=10, train:\")\n",
    "for model in models:\n",
    "    print(cross_val_score(model, X_train_remfeat, y_train_remfeat, cv=n_folds).mean())\n",
    "    \n",
    "remfeat_X_train, remfeat_X_test, remfeat_y_train, remfeat_y_test = train_test_split(\n",
    "    X_train_remfeat, y_train_remfeat, random_state=42\n",
    ")\n",
    "\n",
    "print(\"r2:\")\n",
    "for model in models:\n",
    "    model.fit(remfeat_X_train, remfeat_y_train)\n",
    "    remfeat_y_pred = model.predict(remfeat_X_test)\n",
    "    print(r2_score(remfeat_y_test, remfeat_y_pred))\n",
    "    \n",
    "print(\"rmsle:\")\n",
    "for model in models:\n",
    "    model.fit(remfeat_X_train, remfeat_y_train)\n",
    "    remfeat_y_pred = model.predict(remfeat_X_test)\n",
    "    print(np.sqrt(mean_squared_error(remfeat_y_test, remfeat_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore final datasets again\n",
    "\n",
    "X_train_feateng_cpy = X_train_feateng.copy()\n",
    "\n",
    "continuous_to_bins_inplace(X_train_feateng_cpy, 'LotArea', 20)\n",
    "\n",
    "encode_column_inplace(X_train_feateng_cpy, 'LotArea', 10)\n",
    "encode_column_inplace(X_test_feateng, 'LotArea', 10)\n",
    "\n",
    "display(X_test_feateng.head(10))\n",
    "\n",
    "# _tmp_X_train, _tmp_X_test, _tmp_y_train, _tmp_y_test = train_test_split(\n",
    "#     X_train_feateng_cpy, y_train_feateng, random_state=42\n",
    "# )\n",
    "\n",
    "# model = GradientBoostingRegressor(\n",
    "#     n_estimators=2000, max_features='sqrt', max_depth=100, min_samples_leaf = 4\n",
    "# )\n",
    "# _tmp_y_pred = model.predict(X_test_feateng)\n",
    "\n",
    "# print(\"cross validation k=10\")\n",
    "# print(cross_val_score(model, X_train_feateng_cpy, y_train_feateng, cv=n_folds).mean())\n",
    "\n",
    "# print(\"r2:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters search : without features removal\n",
    "\n",
    "models = [\n",
    "    LassoCV(), RidgeCV(), LinearRegression(), ElasticNetCV(cv=n_folds), BayesianRidge(),\n",
    "    KNeighborsRegressor(), \n",
    "    RandomForestRegressor(), GradientBoostingRegressor(),\n",
    "    XGBRegressor(objective='reg:squarederror'),\n",
    "    SVR(kernel='rbf', gamma=0.1)\n",
    "]\n",
    "\n",
    "models_params = [\n",
    "    {\n",
    "#         'alphas': [0.001, 0.01, 0.02, 0.025, 0.05, 0.1, 0.5, 1, 5],\n",
    "        'n_alphas': [100, 1000, 10000],\n",
    "        'eps': [1e-6, 1e-5, 1e-4, 1e-3, 1, 10],\n",
    "        'max_iter': [1000, 10000, 50000]\n",
    "    },  # {'eps': 1e-05, 'max_iter': 1000, 'n_alphas': 1000}\n",
    "    {\n",
    "        'alpha':[200, 230, 250,265, 270, 275, 290, 300, 500]\n",
    "    },\n",
    "    {\n",
    "        'n_neighbors': [3, 5, 10, 20],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    {\n",
    "        'bootstrap': [True, False],\n",
    "        'n_estimators': [10, 100, 500, 700, 1000, 1500, 2000],\n",
    "        'max_depth': [None, 1, 3, 5, 10, 20, 30, 40, 50, 75, 100],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 3, 5, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "# lasso_params\n",
    "# ridge_params\n",
    "# lr_params\n",
    "# elasticnet_params\n",
    "# b_ridge_params\n",
    "\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    RandomForestRegressor(),\n",
    "    models_params[3],\n",
    "    verbose=2,\n",
    "    cv=n_folds,\n",
    "    n_jobs=-1\n",
    ")\n",
    "gs_results = gs.fit(X_train_feateng, y_train_feateng)\n",
    "\n",
    "display(\n",
    "    gs_results.best_score_,\n",
    "    gs_results.best_estimator_,\n",
    "    gs_results.best_params_\n",
    ")\n",
    "\n",
    "# knn: radial + display circles\n",
    "# svc: rbf kernel, linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters search : with features removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold and LeaveOneOut CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train_remfeat, y_train_remfeat)\n",
    "y_pred_log = model.predict(X_test_remfeat)\n",
    "\n",
    "y_pred = np.exp(y_pred_log)\n",
    "\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions submission\n",
    "\n",
    "submissions_df = pd.DataFrame()\n",
    "submissions_df['Id'] = test_df['Id']\n",
    "submissions_df['SalePrice'] = y_pred \n",
    "\n",
    "submissions_df.to_csv('submission_4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
